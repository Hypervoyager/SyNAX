"""
FedNeurX: å¼‚æ„ç¥ç»ç½‘ç»œè”é‚¦å­¦ä¹ æ¡†æ¶
----------------------------------------------------------------------------
# é¡¹ç›®æè¿°:
# å®ç°ANNè®¾å¤‡ä¸SNNè®¾å¤‡çš„è”åˆè®­ç»ƒ,é€šè¿‡ä¸­å¤®æœåŠ¡å™¨åè°ƒä¸¤ç§å¼‚æ„ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚
# 
# è®­ç»ƒæµç¨‹:
# 1. ä¸­å¤®æœåŠ¡å™¨åŒæ—¶ç»´æŠ¤ANNä¸SNNä¸¤ä¸ªå…¨å±€æ¨¡å‹
# 2. æ¯è½®è®­ç»ƒ,æœåŠ¡å™¨å…ˆå°†ANNå…¨å±€æ¨¡å‹åˆ†å‘ç»™ANNè®¾å¤‡è¿›è¡Œè®­ç»ƒ
# 3. æœåŠ¡å™¨æ”¶é›†å¹¶èšåˆANNè®¾å¤‡çš„å¹³å‡æ¢¯åº¦,æ›´æ–°å…¨å±€ANNæ¨¡å‹
# 4. æœåŠ¡å™¨å°†æ›´æ–°åçš„å…¨å±€ANNæ¨¡å‹è½¬æ¢ä¸ºå…¨å±€SNNæ¨¡å‹
# 5. è®¡ç®—è½¬æ¢å‰åSNNæ¨¡å‹å‚æ•°å·®å¼‚,ç”Ÿæˆæ‰°åŠ¨å‘é‡(zero_direct)
# 6. SNNå®¢æˆ·ç«¯åˆ©ç”¨zero_directæ‰§è¡Œé›¶é˜¶ä¼˜åŒ–:
#    - å¯¹æœ¬åœ°SNNæ¨¡å‹åº”ç”¨æ­£è´Ÿæ‰°åŠ¨(+/-zero_direct)
#    - è®¡ç®—ä¸¤ç§æ‰°åŠ¨ä¸‹çš„æŸå¤±å€¼ï¼Œä¼°ç®—æ¢¯åº¦æ–¹å‘
#    - åŸºäºä¼°ç®—çš„æ¢¯åº¦æ›´æ–°æœ¬åœ°æ¨¡å‹
#
# æ­¤æ–¹æ³•ä½¿å¼‚æ„è®¾å¤‡èƒ½å¤Ÿåœ¨è”é‚¦å­¦ä¹ ç¯å¢ƒä¸­é«˜æ•ˆååŒè®­ç»ƒï¼Œæ— éœ€å…±äº«åŸå§‹æ•°æ®ã€‚
"""

import os
import random
import time

import torch
import ast

from Data import Data
from models.dyrep import DyRep, build_optimizer, get_params
from Node.Node import Global_Node, Node
from Trainer import Trainer
from utils.utils import (LR_scheduler, Recorder, Summary, get_log_file_name,
                         init_args, print_memory_usage, generate_node_list, initialize_device_types, set_random_seed)
from utils_ann2snn import evaluate_snn



# init 
args = init_args()
set_random_seed(args.seed)
lr_initial = args.lr
args.type = 'VIT'
args.shape = 224  # For Vit
# args.capacity_values = generate_node_list(args)

if args.wandb ==1:
    import wandb
    run_name = f"{args.dataset}_num-{args.node_num}_lepoch-{args.E}_lr-{args.lr}_note-{args.notes}"
    wandb.init(project="DyFL", name = run_name, entity="paridis")
    config_dict = vars(args)
    wandb.config.update(config_dict)

Data = Data(args)
Train = Trainer(args)
recorder = Recorder(args)
file_name  = get_log_file_name(args, directory = "logs/log2410")


# init nodes
snn_ratio = 0.5  # SNN è®¾å¤‡æ¯”ä¾‹
ann_devices, snn_devices = initialize_device_types(args.node_num, snn_ratio)
zero_direct = None
Global_node = Global_Node(Data.test_all, args)
Edge_nodes = [
    Node(
        k,
        Data.train_loader[k],
        Data.test_loader,
        args,
        device_type="SNN" if k in snn_devices else "ANN"
    )
    for k in range(args.node_num)
]
device = args.device




# è¶…å‚æ•°
beta = 0.9  # åŠ¨é‡ç³»æ•°
# ann_momentum = None  # åˆå§‹åŒ– ANN è®¾å¤‡çš„å†å²åŠ¨é‡


# è®­ç»ƒå¾ªç¯
for rounds in range(args.R): 
    Summary(args)
    print(f'=============== ç¬¬ {rounds + 1} è½®ï¼Œè®¾å¤‡: {device} ===============')

    args.lr = LR_scheduler(lr_initial, rounds, args.R)

    # **1ï¸âƒ£ è®¾å¤‡æŠ½æ ·**
    sampled_nodes = random.sample(Edge_nodes, int(args.node_num * args.sample_ratio))
    ann_nodes = [node for node in sampled_nodes if node.device_type == "ANN"]
    snn_nodes = [node for node in sampled_nodes if node.device_type == "SNN"]

    Global_node.merge_init()
    scaling_factors = []
    # **2ï¸âƒ£ åŒæ—¶è®­ç»ƒ ANN å’Œ SNN**
    for node in sampled_nodes:
        print(f'---------- è½®æ¬¡: {rounds+1}, è®¾å¤‡: {node.num}, ç±»å‹: {node.device_type} ---------------')

        if node.device_type == "ANN":
            node.ann_fork(Global_node)  # è·å–å…¨å±€æ¨¡å‹
            for epoch in range(args.E):
                Train(node, epoch, rounds, type="ANN")
            Global_node.merge_now(node, device_type="ANN")
            node.delete_model()

        elif node.device_type == "SNN":
            if rounds == 0:
                # åˆå§‹å›åˆsnnè®¾å¤‡ä¸å‚ä¸
                pass
            else:
                node.snn_fork(Global_node, zero_direct)  # **ä½¿ç”¨ ANN çš„å†å²åŠ¨é‡**
                
                for epoch in range(args.E):
                    node.model = node.get_perturbed_model(zero_direct, sign=1)   # æ–¹å‘ "+"
                    loss_plus = Train(node, epoch, rounds, type="SNN")

                    node.model = node.get_perturbed_model(zero_direct, sign=-2) # æ–¹å‘ "-"
                    loss_minus = Train(node, epoch, rounds, type="SNN")

                    node.model = node.get_perturbed_model(zero_direct, sign=1) # å¤ä½

                    node.zero_order_update(loss_plus, loss_minus, zero_direct)
                    scaling_factors.append(node.scaling_factor)
                node.delete_model()

    # èŠ‚ç‚¹è®­ç»ƒå®Œæˆï¼Œå¼€å§‹èšåˆ
    if len(ann_nodes) == 0:
        pass
    else:
        zero_direct, norm = Global_node.finish_merge_momentum(num_nodes=len(ann_nodes), beta = args.zero_momentum)
        
    if len(scaling_factors) == 0:
        pass
    else:
        avg_scaling_factor = sum(scaling_factors) / len(scaling_factors)
        avg_scaling_factor =  max(args.zero_min, min(args.zero_max, avg_scaling_factor))
        print(f"ğŸ“¢ å¹³å‡ Scaling Factor: {avg_scaling_factor:.4f}")
        print(f"ğŸ“¢ é˜ˆå€¼: {args.zero_min}, {args.zero_max}")
        Global_node.aggregate_snn(avg_scaling_factor)
        if node.args.wandb ==1:
            import wandb
            wandb.log({node.args.dataset + "_Scaling Factor": avg_scaling_factor}, step = rounds)
    
    recorder.validate(Global_node)
    recorder.printer(Global_node, file_name=file_name, rounds=rounds)

test_stats = evaluate_snn(Global_node.test_data, Global_node.snn_model, device, args.test_T, args)

Summary(args)