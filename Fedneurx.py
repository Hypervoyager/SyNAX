"""
FedNeurX: å¼‚æ„ç¥ç»ç½‘ç»œè”é‚¦å­¦ä¹ æ¡†æ¶
----------------------------------------------------------------------------
# é¡¹ç›®æè¿°:
# å®ç°ANNè®¾å¤‡ä¸SNNè®¾å¤‡çš„è”åˆè®­ç»ƒ,é€šè¿‡ä¸­å¤®æœåŠ¡å™¨åè°ƒä¸¤ç§å¼‚æ„ç¥ç»ç½‘ç»œæ¨¡å‹ã€‚
# 
# è®­ç»ƒæµç¨‹:
# 1. ä¸­å¤®æœåŠ¡å™¨åŒæ—¶ç»´æŠ¤ANNä¸SNNä¸¤ä¸ªå…¨å±€æ¨¡å‹
# 2. æ¯è½®è®­ç»ƒ,æœåŠ¡å™¨å…ˆå°†ANNå…¨å±€æ¨¡å‹åˆ†å‘ç»™ANNè®¾å¤‡è¿›è¡Œè®­ç»ƒ
# 3. æœåŠ¡å™¨æ”¶é›†å¹¶èšåˆANNè®¾å¤‡çš„å¹³å‡æ¢¯åº¦,æ›´æ–°å…¨å±€ANNæ¨¡å‹
# 4. æœåŠ¡å™¨å°†æ›´æ–°åçš„å…¨å±€ANNæ¨¡å‹è½¬æ¢ä¸ºå…¨å±€SNNæ¨¡å‹
# 5. è®¡ç®—è½¬æ¢å‰åSNNæ¨¡å‹å‚æ•°å·®å¼‚,ç”Ÿæˆæ‰°åŠ¨å‘é‡(zero_direct)
# 6. SNNå®¢æˆ·ç«¯åˆ©ç”¨zero_directæ‰§è¡Œé›¶é˜¶ä¼˜åŒ–:
#    - å¯¹æœ¬åœ°SNNæ¨¡å‹åº”ç”¨æ­£è´Ÿæ‰°åŠ¨(+/-zero_direct)
#    - è®¡ç®—ä¸¤ç§æ‰°åŠ¨ä¸‹çš„æŸå¤±å€¼ï¼Œä¼°ç®—æ¢¯åº¦æ–¹å‘
#    - åŸºäºä¼°ç®—çš„æ¢¯åº¦æ›´æ–°æœ¬åœ°æ¨¡å‹
#
# æ­¤æ–¹æ³•ä½¿å¼‚æ„è®¾å¤‡èƒ½å¤Ÿåœ¨è”é‚¦å­¦ä¹ ç¯å¢ƒä¸­é«˜æ•ˆååŒè®­ç»ƒï¼Œæ— éœ€å…±äº«åŸå§‹æ•°æ®ã€‚
"""

import os
import random
import time

import torch
import ast

from Data import Data
from models.dyrep import DyRep, build_optimizer, get_params
from Node.Node import Global_Node, Node
from Trainer import Trainer
from utils.utils import (LR_scheduler, Recorder, Summary, get_log_file_name,
                         init_args, print_memory_usage, generate_node_list, initialize_device_types, set_random_seed)
from utils_ann2snn import evaluate_snn



# init 
args = init_args()
set_random_seed(args.seed)
lr_initial = args.lr
args.type = 'VIT'
args.shape = 224  # For Vit
# args.capacity_values = generate_node_list(args)

if args.wandb ==1:
    import wandb
    run_name = f"{args.dataset}_num-{args.node_num}_lepoch-{args.E}_lr-{args.lr}_note-{args.notes}"
    wandb.init(project="DyFL", name = run_name, entity="paridis")
    config_dict = vars(args)
    wandb.config.update(config_dict)

Data = Data(args)
Train = Trainer(args)
recorder = Recorder(args)
file_name  = get_log_file_name(args, directory = "logs/log2410")


# init nodes
snn_ratio = 0.5  # SNN è®¾å¤‡æ¯”ä¾‹
ann_devices, snn_devices = initialize_device_types(args.node_num, snn_ratio)
Global_node = Global_Node(Data.test_all, args)
Edge_nodes = [
    Node(
        k,
        Data.train_loader[k],
        Data.test_loader,
        args,
        device_type="SNN" if k in snn_devices else "ANN"
    )
    for k in range(args.node_num)
]
device = args.device


# train
for rounds in range(args.R): 
    Summary(args)
    print('===============The {:d}-th round, device: {:s}==============='.format(rounds + 1, str(device)))
    args.lr = LR_scheduler(lr_initial, rounds, args.R)
    # æŒ‰è®¾å¤‡ç±»å‹åˆ†ç±»
    # ann_nodes = [node for node in Edge_nodes if node.device_type == "ANN"]
    # snn_nodes = [node for node in Edge_nodes if node.device_type == "SNN"]

    # å…¨éƒ¨è®¾å¤‡
    full_ann_nodes = [node for node in Edge_nodes if node.device_type == "ANN"]
    full_snn_nodes = [node for node in Edge_nodes if node.device_type == "SNN"]

    # å®¢æˆ·ç«¯é‡‡æ ·
    sample_size_ann = max(1, int(len(full_ann_nodes) * args.client_sample_ratio))
    sample_size_snn = max(1, int(len(full_snn_nodes) * args.client_sample_ratio))

    ann_nodes = random.sample(full_ann_nodes, sample_size_ann)
    snn_nodes = random.sample(full_snn_nodes, sample_size_snn)
    Global_node.merge_init()
    # è®­ç»ƒ ANN è®¾å¤‡
    for index, node in enumerate(ann_nodes):
        print(f'---------- Rounds: {rounds+1}, ANN Node: {node.num}, Notes: {args.notes} ---------------')
        node.ann_fork(Global_node)  # edge_node get global model
        for epoch in range(args.E):
            Train(node, epoch, rounds, type = "ANN")
        Global_node.merge_now(node, device_type="ANN")
        node.delete_model()

    zero_direct, norm = Global_node.finish_merge(num_nodes=len(ann_nodes), device_type="ANN")


    if args.mode == 'ann_only':  # åªæœ‰ANNæ¨¡å‹
        print("ğŸš€ æ²¡æœ‰ SNN è®¾å¤‡ï¼Œè·³è¿‡ SNN è®­ç»ƒï¼Œç›´æ¥è¿›è¡Œ ANN è®­ç»ƒç»“æœèšåˆã€‚")
    elif args.mode == 'FedNeurx':
        # è®­ç»ƒ SNN è®¾å¤‡
        scaling_factors = []
        for index, node in enumerate(snn_nodes):
            print(f'---------- Rounds: {rounds+1}, SNN Node: {node.num}, Notes: {args.notes} ---------------')
            node.snn_fork(Global_node, zero_direct)  # edge_node get global model

            for epoch in range(args.E):
                # 2ï¸âƒ£ è®¡ç®—æ‰°åŠ¨æ–¹å‘çš„ SNN æ¨¡å‹å‚æ•°
                node.model = node.get_perturbed_model(zero_direct, sign=1)   # æ–¹å‘ "+"
                loss_plus = Train(node, epoch, rounds, type="SNN")

                node.model = node.get_perturbed_model(zero_direct, sign=-2) # æ–¹å‘ "-"
                loss_minus = Train(node, epoch, rounds, type="SNN")

                node.model = node.get_perturbed_model(zero_direct, sign=1) # å¤ä½

                # 4ï¸âƒ£ ä¼°è®¡æ‰°åŠ¨ç³»æ•°
                node.zero_order_update(loss_plus, loss_minus, zero_direct)
                scaling_factors.append(node.scaling_factor)
            node.delete_model()

        avg_scaling_factor = sum(scaling_factors) / len(scaling_factors)
        avg_scaling_factor =  max(args.zero_min, min(args.zero_max, avg_scaling_factor))
        print(f"ğŸ“¢ å¹³å‡ Scaling Factor: {avg_scaling_factor:.4f}")
        print(f"ğŸ“¢ é˜ˆå€¼: {args.zero_min}, {args.zero_max}")
        Global_node.aggregate_snn(avg_scaling_factor)

    recorder.validate(Global_node)
    recorder.printer(Global_node, file_name = file_name, rounds = rounds)
test_stats = evaluate_snn(Global_node.test_data, Global_node.snn_model, device,args.test_T,args)

Summary(args)